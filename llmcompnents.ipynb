{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673806a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Category-wise Spending:\n",
      " Category\n",
      "Bills       301074.10\n",
      "Recharge    295007.36\n",
      "Travel      288358.07\n",
      "Transfer    276507.37\n",
      "Shopping    262050.13\n",
      "Food        258078.13\n",
      "Rent        207336.48\n",
      "Others      202814.88\n",
      "Name: Amount, dtype: float64\n",
      "\n",
      "ğŸ—“ï¸ Spending by Day:\n",
      " DayOfWeek\n",
      "Friday       329668.96\n",
      "Tuesday      319019.79\n",
      "Saturday     313395.21\n",
      "Wednesday    299240.02\n",
      "Monday       283794.53\n",
      "Thursday     273469.58\n",
      "Sunday       272638.43\n",
      "Name: Amount, dtype: float64\n",
      "\n",
      "â° Spending by Hour:\n",
      " Hour\n",
      "7     117506.49\n",
      "18    114689.94\n",
      "17    111276.58\n",
      "4     107740.15\n",
      "11    103675.06\n",
      "15    100165.80\n",
      "19     98216.24\n",
      "22     96057.32\n",
      "20     95879.90\n",
      "6      95574.41\n",
      "23     90853.71\n",
      "9      85889.50\n",
      "5      82470.65\n",
      "13     82006.66\n",
      "21     81058.51\n",
      "16     78995.98\n",
      "14     75681.46\n",
      "2      74020.58\n",
      "8      73457.00\n",
      "1      70811.12\n",
      "3      69580.96\n",
      "0      68208.32\n",
      "12     66096.69\n",
      "10     51313.49\n",
      "Name: Amount, dtype: float64\n",
      "\n",
      "ğŸª Top 5 Merchants:\n",
      " Receiver\n",
      "Smith and Sons    9697.41\n",
      "Miller Ltd        9266.85\n",
      "Price Group       8156.61\n",
      "Walker Inc        7751.38\n",
      "Hernandez Inc     7544.49\n",
      "Name: Amount, dtype: float64\n",
      "\n",
      "âš ï¸ Potential Wasteful Transactions (Small & Repetitive):\n",
      " Series([], dtype: int64)\n",
      "\n",
      "âš ï¸ Transactions with Pending/Failed Status:\n",
      "           Date                     Receiver   Amount   Status\n",
      "0   2024-09-20       Obrien, Wood and Smith   580.17  PENDING\n",
      "1   2024-09-20        Garner, Wilson and Le  2887.24  PENDING\n",
      "5   2024-09-22                    Evans Inc   427.68  PENDING\n",
      "6   2024-09-22       Price, Brown and Singh  1708.82  PENDING\n",
      "7   2024-09-23  Knight, Perkins and Johnson  1669.45  PENDING\n",
      "..         ...                          ...      ...      ...\n",
      "817 2025-09-15                   Garcia Inc  2206.21  PENDING\n",
      "821 2025-09-17                   Harris PLC  2656.72  PENDING\n",
      "823 2025-09-18                     Dunn Ltd  3291.61  PENDING\n",
      "824 2025-09-19                   Nelson Ltd  1495.21  PENDING\n",
      "825 2025-09-20                   Franco-Gay  4879.43  PENDING\n",
      "\n",
      "[441 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\staru\\AppData\\Local\\Temp\\ipykernel_5164\\1415215955.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Hour'] = pd.to_datetime(df['Time']).dt.hour\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/staru/Desktop/upi/updated_data.csv\")\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')\n",
    "df['DayOfWeek'] = df['Date'].dt.day_name()\n",
    "df['Hour'] = pd.to_datetime(df['Time']).dt.hour\n",
    "df['Month'] = df['Date'].dt.to_period('M')\n",
    "\n",
    "category_summary = df.groupby(\"Category\")[\"Amount\"].sum().sort_values(ascending=False)\n",
    "print(\"\\nğŸ“Š Category-wise Spending:\\n\", category_summary)\n",
    "\n",
    "day_summary = df.groupby(\"DayOfWeek\")[\"Amount\"].sum().sort_values(ascending=False)\n",
    "hour_summary = df.groupby(\"Hour\")[\"Amount\"].sum().sort_values(ascending=False)\n",
    "print(\"\\nğŸ—“ï¸ Spending by Day:\\n\", day_summary)\n",
    "print(\"\\nâ° Spending by Hour:\\n\", hour_summary)\n",
    "\n",
    "top_merchants = df.groupby(\"Receiver\")[\"Amount\"].sum().sort_values(ascending=False).head(5)\n",
    "print(\"\\nğŸª Top 5 Merchants:\\n\", top_merchants)\n",
    "\n",
    "small_transactions = df[df['Amount'] < 500]\n",
    "recurring = small_transactions.groupby(['Receiver','Month']).size()\n",
    "wasteful_small = recurring[recurring > 3]\n",
    "\n",
    "wasteful_status = df[df['Status'].isin(['PENDING', 'FAILED'])]\n",
    "\n",
    "print(\"\\nâš ï¸ Potential Wasteful Transactions (Small & Repetitive):\\n\", wasteful_small)\n",
    "print(\"\\nâš ï¸ Transactions with Pending/Failed Status:\\n\", wasteful_status[['Date','Receiver','Amount','Status']])\n",
    "\n",
    "category_totals = category_summary.to_dict()\n",
    "day_totals = day_summary.to_dict()\n",
    "hour_totals = hour_summary.to_dict()\n",
    "merchant_totals = top_merchants.to_dict()\n",
    "small_recurring_dict = wasteful_small.to_dict()\n",
    "failed_pending_dict = wasteful_status.to_dict(orient='records')\n",
    "\n",
    "llm_prompt = f\"\"\"\n",
    "I have a UPI transaction dataset. Please provide insights:\n",
    "1. Spending patterns by category: {category_totals}\n",
    "2. Spending by day: {day_totals}\n",
    "3. Spending by hour: {hour_totals}\n",
    "4. Top 5 merchants: {merchant_totals}\n",
    "5. Potential wasteful\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec96287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models in your project:\n",
      "models/embedding-gecko-001 â†’ supports: ['embedText', 'countTextTokens']\n",
      "models/gemini-2.5-pro-preview-03-25 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-05-20 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-06-17 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-05-06 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-06-05 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp â†’ supports: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-001 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp-image-generation â†’ supports: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-lite-001 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-preview-image-generation â†’ supports: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp-02-05 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-exp-1206 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-1219 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-tts â†’ supports: ['countTokens', 'generateContent']\n",
      "models/gemini-2.5-pro-preview-tts â†’ supports: ['countTokens', 'generateContent']\n",
      "models/learnlm-2.0-flash-experimental â†’ supports: ['generateContent', 'countTokens']\n",
      "models/gemma-3-1b-it â†’ supports: ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it â†’ supports: ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it â†’ supports: ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it â†’ supports: ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e4b-it â†’ supports: ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e2b-it â†’ supports: ['generateContent', 'countTokens']\n",
      "models/gemini-flash-latest â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-flash-lite-latest â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-pro-latest â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-image-preview â†’ supports: ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-preview-09-2025 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-09-2025 â†’ supports: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-robotics-er-1.5-preview â†’ supports: ['generateContent', 'countTokens']\n",
      "models/embedding-001 â†’ supports: ['embedContent']\n",
      "models/text-embedding-004 â†’ supports: ['embedContent']\n",
      "models/gemini-embedding-exp-03-07 â†’ supports: ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-exp â†’ supports: ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-001 â†’ supports: ['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n",
      "models/aqa â†’ supports: ['generateAnswer']\n",
      "models/imagen-3.0-generate-002 â†’ supports: ['predict']\n",
      "models/imagen-4.0-generate-preview-06-06 â†’ supports: ['predict']\n",
      "models/imagen-4.0-ultra-generate-preview-06-06 â†’ supports: ['predict']\n",
      "models/imagen-4.0-generate-001 â†’ supports: ['predict']\n",
      "models/imagen-4.0-ultra-generate-001 â†’ supports: ['predict']\n",
      "models/imagen-4.0-fast-generate-001 â†’ supports: ['predict']\n",
      "models/veo-2.0-generate-001 â†’ supports: ['predictLongRunning']\n",
      "models/veo-3.0-generate-preview â†’ supports: ['predictLongRunning']\n",
      "models/veo-3.0-fast-generate-preview â†’ supports: ['predictLongRunning']\n",
      "models/veo-3.0-generate-001 â†’ supports: ['predictLongRunning']\n",
      "models/veo-3.0-fast-generate-001 â†’ supports: ['predictLongRunning']\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog â†’ supports: ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.5-flash-exp-native-audio-thinking-dialog â†’ supports: ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-live-001 â†’ supports: ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-live-2.5-flash-preview â†’ supports: ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-live-preview â†’ supports: ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-native-audio-latest â†’ supports: ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025 â†’ supports: ['countTokens', 'bidiGenerateContent']\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"")\n",
    "\n",
    "print(\"Available Models in your project:\")\n",
    "for m in genai.list_models():\n",
    "    print(m.name, \"â†’ supports:\", m.supported_generation_methods)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
